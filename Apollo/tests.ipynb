{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from Conversation.serializers import *\n",
    "from Conversation.converse.core import Message\n",
    "from Conversation.converse.prompts import *\n",
    "from Conversation.converse.tools import *\n",
    "\n",
    "from turbochat.gptprompts import *\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import cerberus\n",
    "\n",
    "from Apollo.settings import GPT_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Message:\n",
    "\n",
    "    def __init__(self, prompt, context={}, system_instructions=None, history=None, tools: Tools=None) -> None:\n",
    "        \n",
    "        self.context = context\n",
    "        self.prompt = str(prompt)\n",
    "        self.prompt = self.prompt.format(**context)\n",
    "\n",
    "        self.system_instructions = system_instructions\n",
    "        self.history = history\n",
    "\n",
    "        if tools and not isinstance(tools, Tools):\n",
    "            raise TypeError(\"tools should be of instance Tools\")\n",
    "        \n",
    "        self.tools =  tools\n",
    "        self.response, self.tool_response = self.call_gpt()\n",
    "        \n",
    "\n",
    "    def make_message(self):\n",
    "        \n",
    "        system = System(self.system_instructions)\n",
    "        user_prompt = User(self.prompt)\n",
    "\n",
    "        if self.history:\n",
    "            history_messages = Messages.from_text(self.history)\n",
    "            prompts = [system] + history_messages.prompts + [user_prompt]\n",
    "\n",
    "        else: prompts = [system, user_prompt]\n",
    "\n",
    "        return Messages(prompts)\n",
    "    \n",
    "\n",
    "    def call_gpt(self):\n",
    "\n",
    "        message = self.make_message()\n",
    "\n",
    "        client = OpenAI(api_key=GPT_KEY)\n",
    "     \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=message.get_entries()\n",
    "        )\n",
    "\n",
    "\n",
    "        tool_response = None\n",
    "        if self.tools:\n",
    "            tool_response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=message.get_entries(),\n",
    "                tools = self.tools.get_tools(),\n",
    "                tool_choice=\"required\" # auto, required, disabled\n",
    "            )\n",
    "\n",
    "        return response, tool_response\n",
    "\n",
    "\n",
    "    def get_history(self, apetite=30):\n",
    "        # will keep combination of\n",
    "        messages = self.make_message()\n",
    "        user = User(self.context.get(\"message\", \"\"))\n",
    "        prompts = messages.prompts[1:-1]\n",
    "        prompts = prompts[apetite*-2:]\n",
    "        prompts.append(user)\n",
    "        return Messages(prompts).to_text()\n",
    "\n",
    "\n",
    "    def get_results(self):\n",
    "\n",
    "        reply = self.response.choices[0].message.content\n",
    "        tool_calls = {}\n",
    "        \n",
    "        if self.tool_response:\n",
    "            tool_calls = {}\n",
    "            tool_calls = self.tools.get_results(self.tool_response, tool_calls)\n",
    "\n",
    "        return reply, tool_calls\n",
    "\n",
    "\n",
    "class Prompt:\n",
    "\n",
    "    def __init__(self, prompt, context, default=\"\") -> None:\n",
    "        self.prompt = str(prompt)\n",
    "        self.maps = self.consume(prompt, context, default=\"\")\n",
    "\n",
    "\n",
    "    def consume(self, prompt, context={}, default=\"\"):\n",
    "\n",
    "        required_context = re.findall(r'\\{([^}]*)\\}', USER_PROMPT_DEFAULT)\n",
    "        for key in required_context:\n",
    "            if key not in context: context[key] = default\n",
    "\n",
    "        prompt = prompt.format(**context)\n",
    "\n",
    "        splits = [x.strip('\\n') for x in prompt.split(\"#\")]\n",
    "        splits = [x.split('\\n') for x in splits if x]\n",
    "        splits = {x[0].strip().replace(\":\", \"\"): \"\\n\".join(x[1:]).strip() for x in splits if len(x) >= 2}\n",
    "        \n",
    "        return splits\n",
    "\n",
    "\n",
    "    def get_format(self, keys: list, key_value_format=lambda k, v: f\"{k}:\\n{v}\", join_with='\\n\\n'):\n",
    "        \n",
    "        if not all(key in self.maps for key in keys):\n",
    "            raise ValueError(\"not all keys present in the prompt\")\n",
    "        \n",
    "        outs = [key_value_format(key, self.maps[key]) for key in keys]\n",
    "        return join_with.join(outs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collected_health_information_entries(entries):\n",
    "    df = pd.DataFrame(entries)\n",
    "    df.columns = [\"i_parameter_label\", \"parameter_type\", \"parameter_value\"]\n",
    "    return df\n",
    "\n",
    "CONVERSE_TOOLS = Tools([\n",
    "    {\n",
    "        \"name\": \"collected_health_information_entries\",\n",
    "        \"function\": collected_health_information_entries,\n",
    "        \"definition\": EXTRACT_USER_RELATED_INFO\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_answered_tool_definition = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"questions_answered\",\n",
    "        \"description\": \"\"\"\n",
    "            This function will be called whenever the previous response from assistant has questions.\n",
    "            looking at assistant previous response and user message determine's which questions were answered by the user.\n",
    "            this function will list down all the questions and answers to them provided by user.\n",
    "            If user has provided no answers set answer as \"NAN\"\n",
    "            If no questions where asked return empty\n",
    "        \"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"questions\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"list of questions asked by assistant and their answers provided by user in user message\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \n",
    "                            \"question\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"\"\"\n",
    "                                    question asked by assistant\n",
    "                                \"\"\"\n",
    "                            },\n",
    "\n",
    "\n",
    "                            \"subject\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"\"\"\n",
    "                                    one word subject of the question.\n",
    "                                \"\"\"\n",
    "                            },\n",
    "                            \n",
    "                            \"answer\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"\"\"\n",
    "                                    answer provided in the user message.\n",
    "                                    If answer is not provided it should be set to \"NAN\"\n",
    "                                \"\"\"\n",
    "                            },\n",
    "                        \n",
    "                        },\n",
    "                        \"required\": [\"questions\", \"subject\", \"answer\"],\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"questions\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "user_other_mentions_tool_definition = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"user_other_mentions\",\n",
    "        \"description\": \"\"\"\n",
    "            This function will be called whenever user mentions something in response to assistant.\n",
    "            From assistant previous response and user message identify what user is trying to mention which is not asked by the assistant.\n",
    "            If no questions where asked return empty\n",
    "        \"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"mentions\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"list of other mentions by the user\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \n",
    "                            \"context\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"\"\"\n",
    "                                    very short context to what user is trying to mention with the reasons if any mentioned.\n",
    "                                \"\"\"\n",
    "                            },\n",
    "\n",
    "\n",
    "                            \"subject\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"\"\"\n",
    "                                    one word subject for the user mentioned context.\n",
    "                                \"\"\"\n",
    "                            },\n",
    "                            \n",
    "                            \"key_highlight\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"\"\"\n",
    "                                    1 word key that was highligted in the user's context that will describe the subject\n",
    "                                \"\"\"\n",
    "                            },\n",
    "                        \n",
    "                        },\n",
    "                        \"required\": [\"context\", \"subject\", \"key_highlight\"],\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"mentions\"],\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"\n",
    "ALWAYS KEEP CONVERSATION SHORT AND TO THE POINT.\n",
    "Collect as much information about the user as possible by asking QUESTIONS and chaining conversation.\n",
    "Collect information regarding their habits, mental, physical health, medical conditions, reports, tests, lifestyle choices preferences etc. Everything which is an indicator of a user's health.\n",
    "Always ask for medical test reports related to user's health issues. If user does not have one suggest them to take the required tests. Also list them what reports/tests are required for the same.\n",
    "Give more importance information provided through medical tests/reports by the user.\n",
    "Whatever user enquires about ask follow up QUESTIONS around the topic to engage the user in multiple conversation chain.\n",
    "If conversation goes off topic, acknowledge the user's responses and get the conversation back to health and lifestyle.\n",
    "Suggest small goals to user in order to resolve their problem.\n",
    "User's medical history will be provided in the user's response, ALWAYS consider the user's past history while collecting user's information.\n",
    "ALWAYS END YOUR CONVERSATION WITH A QUESTION. NEVER STOP A CONVERSATION. ONCE THE CONVERSATION CHAIN IS OVER QUICKLY CHANGE TO RELATED TOPICS BY ASKING MORE QUESTIONS. KEEP THE CONVERSATION SHORT. DONT ASK EVERYTHING IN THE SAME RESPONSE.\n",
    "If you think user is mistaken, give response with reference to user's previous prompt.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_DEFAULT = \"\"\"\n",
    "\n",
    "# conversation state:\n",
    "{state}\n",
    "\n",
    "\n",
    "# conversation topic:\n",
    "{topic}\n",
    "\n",
    "\n",
    "# user history:\n",
    "{history}\n",
    "\n",
    "\n",
    "# user goals:\n",
    "{goals}\n",
    "\n",
    "\n",
    "# user events:\n",
    "{events}\n",
    "\n",
    "\n",
    "# Available provider:\n",
    "{providers}\n",
    "\n",
    "\n",
    "# Available doctors:\n",
    "{doctors}\n",
    "\n",
    "\n",
    "# assistant previous response:\n",
    "{assistant_previous_response}\n",
    "\n",
    "\n",
    "# user reply:\n",
    "{user_reply}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant previous response:\n",
      "It's important to listen to your body and take care of yourself, especially if you feel like you've been overworking recently. Have you noticed any specific symptoms or signs of overwork, such as fatigue, muscle pain, or trouble sleeping? How have you been managing your stress levels and self-care practices lately? It might be helpful to prioritize relaxation and self-care activities to help you recharge. Do you have any upcoming appointments with a healthcare provider, or have you discussed this with a doctor or therapist before?\n",
      "\n",
      "user reply:\n",
      "Yes I do have problem sleeping and red eyes in morning after I wake up.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def to_df(questions):\n",
    "    return pd.DataFrame(questions)\n",
    "\n",
    "\n",
    "CONVERSE_TOOLS = Tools([\n",
    "    # {\n",
    "    #     \"name\": \"questions_answered\",\n",
    "    #     \"function\": lambda questions: pd.DataFrame(questions),\n",
    "    #     \"definition\": questions_answered_tool_definition\n",
    "    # },\n",
    "    {\n",
    "        \"name\": \"user_other_mentions\",\n",
    "        \"function\": lambda mentions: pd.DataFrame(mentions),\n",
    "        \"definition\": user_other_mentions_tool_definition\n",
    "    },\n",
    "])\n",
    "\n",
    "question_was_asked_and_answered_context = {\n",
    "    \"state\": \"engaging\",\n",
    "    \"assistant_previous_response\": \"It's important to listen to your body and take care of yourself, especially if you feel like you've been overworking recently. Have you noticed any specific symptoms or signs of overwork, such as fatigue, muscle pain, or trouble sleeping? How have you been managing your stress levels and self-care practices lately? It might be helpful to prioritize relaxation and self-care activities to help you recharge. Do you have any upcoming appointments with a healthcare provider, or have you discussed this with a doctor or therapist before?\",\n",
    "    \"user_reply\": \"Yes I do have problem sleeping and red eyes in morning after I wake up.\"\n",
    "}\n",
    "\n",
    "prompts = Prompt(USER_PROMPT_DEFAULT, question_was_asked_and_answered_context)\n",
    "print(prompts.get_format([\"assistant previous response\", \"user reply\"]))\n",
    "\n",
    "# message = Message(USER_PROMPT_DEFAULT, question_was_asked_and_answered_context, SYSTEM_MESSAGE, history=None, tools=CONVERSE_TOOLS)\n",
    "# reply, tool_calls = message.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = message.tool_response\n",
    "\n",
    "req.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any\n",
    "\n",
    "from turbochat.gptprompts import Messages\n",
    "\n",
    "\n",
    "class GPT:\n",
    "\n",
    "\n",
    "    def __init__(self, api_key, model=\"gpt-3.5-turbo\") -> None:\n",
    "        self.client = OpenAI(api_key=GPT_KEY)\n",
    "        self.model = model\n",
    "\n",
    "    \n",
    "    def call(self, **kwargs):\n",
    "        return self.client.chat.completions.create(model=self.model, **kwargs)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_response_entry(response, return_first=True):\n",
    "        \n",
    "        if len(response.choices):\n",
    "            \n",
    "            if return_first: return response.choices[0].message.to_dict()\n",
    "            else:\n",
    "                return [msg.to_dict() for msg in response.choices]\n",
    "\n",
    "        return None\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def get_reply(response, return_first=True):\n",
    "        if len(response.choices):\n",
    "            \n",
    "            if return_first: return response.choices[0].message.content\n",
    "            else:\n",
    "                return [msg.content for msg in response.choices]\n",
    "\n",
    "\n",
    "class GPTCallable:\n",
    "\n",
    "    def __init__(self, gpt: GPT, messages: Messages):\n",
    "\n",
    "        if not isinstance(gpt, GPT): raise TypeError(\"expected type for gpt: GPT\")\n",
    "        \n",
    "        if not isinstance(messages, Messages): raise TypeError(\"expected type for messages: Messages\")\n",
    "\n",
    "        self.gpt = gpt\n",
    "        self.messages = messages\n",
    "\n",
    "\n",
    "    def _call(self): raise NotImplementedError\n",
    "\n",
    "    \n",
    "    def call(self):\n",
    "        response = self._call(self)\n",
    "        response_entry = GPT.get_response_entry(response)\n",
    "        return response, response_entry\n",
    "\n",
    "\n",
    "class ToolCall(GPTCallable):\n",
    "\n",
    "\n",
    "    def __init__(self, gpt: GPT, messages: Messages, tool: Tools, required=False):\n",
    "        super().__init__(gpt, messages)\n",
    "\n",
    "        if not isinstance(tool, Tools): raise TypeError(\"expected type for tool: Tools\")\n",
    "        \n",
    "        self.tool = tool\n",
    "        self.required = required\n",
    "\n",
    "    \n",
    "    def _call(self):\n",
    "        response = self.gpt.call(messages=self.messages.get_entries(), tools=self.tool.get_tools(), tool_choice=self.required)\n",
    "        return response\n",
    "    \n",
    "\n",
    "    def call(self):\n",
    "        response, response_entry = super().call()\n",
    "        results = self.get_tool_results(response)\n",
    "        return response, response_entry, results\n",
    "\n",
    "\n",
    "    def get_tool_results(self, response):\n",
    "        result = {}\n",
    "        result = self.tool.get_results(response, result)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Msg(GPTCallable):\n",
    "\n",
    "    def __init__(self, gpt: GPT, messages: Messages):\n",
    "        super().__init__(gpt, messages)\n",
    "\n",
    "        self.gpt = gpt\n",
    "        self.messages = messages\n",
    "\n",
    "    def _call(self):\n",
    "        response = self.gpt.call(messages=self.messages.get_entries())\n",
    "        return response\n",
    "\n",
    "    def call(self):\n",
    "        response, response_entry = super().call()\n",
    "        result = GPT.get_reply(response)\n",
    "        return response, response_entry, result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt = GPT(GPT_KEY, model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "USER_CONTENT_SCHEMA = {\n",
    "    \"role\": {\"type\": \"string\", \"required\": True, \"empty\": False, \"allowed\": [\"user\"]},\n",
    "    \"content\": {\n",
    "        \"type\": \"list\", \"required\": True, \"empty\": False, \"nullable\": True, \"schema\": {\n",
    "\n",
    "            \"anyof\": [\n",
    "\n",
    "                {\n",
    "                    \"type\": \"dict\", \"empty\": False, \"schema\": {\n",
    "\n",
    "                        \"type\": { \"type\": \"string\", \"required\": True, \"empty\": False, \"allowed\": [\"text\"] },\n",
    "                        \"content\": { \"type\": \"string\", \"required\": True, \"empty\": True }\n",
    "\n",
    "                    }\n",
    "                },\n",
    "\n",
    "\n",
    "                {\n",
    "                    \"type\": \"dict\", \"empty\": False, \"schema\": {\n",
    "\n",
    "                        \"type\": { \"type\": \"string\", \"required\": True, \"empty\": False, \"allowed\": [\"image_url\"] },\n",
    "                        \"image_url\": { \"type\": \"string\", \"required\": True, \"empty\": False, \"check_with\": \"image_url\" }\n",
    "\n",
    "                    }\n",
    "                },\n",
    "\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "gpt = GPT(GPT_KEY)\n",
    "# response = gpt.call(\n",
    "#     messages=[\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": [\n",
    "#         {\n",
    "#           \"type\": \"text\",\n",
    "#           \"text\": \"What are in these images? Is there any difference between them?\",\n",
    "#         },\n",
    "#         {\n",
    "#           \"type\": \"text\",\n",
    "#           \"text\": \"What are in these images? Is there any difference between them?\",\n",
    "#         }\n",
    "#       ],\n",
    "#     }\n",
    "#   ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"I'm sorry, but as an AI text-based model, I am unable to view images. Could you please provide a description or context for the images so that I can assist you better?\",\n",
       " 'role': 'assistant'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear about your sleeping issues and red eyes in the morning. It's important to address these symptoms to improve your overall health. Have you ever had a sleep study done to check for any sleep disorders such as sleep apnea? This test can provide valuable insights into your sleeping patterns and help identify any underlying issues that may be affecting your sleep quality. Would you be willing to consider undergoing a sleep study to investigate your sleep problems further?\n",
      "\n",
      "\n",
      "| context             | subject   | key_highlight   |\n",
      "|:--------------------|:----------|:----------------|\n",
      "| problem sleeping    | sleeping  | sleeping        |\n",
      "| red eyes in morning | eyes      | eyes            |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reply)\n",
    "print('\\n')\n",
    "\n",
    "for key in tool_calls:\n",
    "    result = tool_calls[key]\n",
    "    # print(result)\n",
    "    print(result[0].to_markdown(index=False))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_was_asked_and_answered_context = {\n",
    "    \"state\": \"engaging\",\n",
    "    \"topic\": \"\",\n",
    "    \"history\": \"\",\n",
    "    \"goals\": \"\",\n",
    "    \"events\": \"\",\n",
    "    \"providers\": \"\",\n",
    "    \"doctors\": \"\",\n",
    "    \"assistant_previous_response\": \"It's important to listen to your body and take care of yourself, especially if you feel like you've been overworking recently. Have you noticed any specific symptoms or signs of overwork, such as fatigue, muscle pain, or trouble sleeping? How have you been managing your stress levels and self-care practices lately? It might be helpful to prioritize relaxation and self-care activities to help you recharge. Do you have any upcoming appointments with a healthcare provider, or have you discussed this with a doctor or therapist before?\",\n",
    "    \"user_reply\": \"Yes I do have problem sleeping and red eyes in morning after I wake up.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
