{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turbochat V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turbochat.v1.prompt import GPTMsges, GPTToolPrompt\n",
    "from turbochat.v1.gpt import GPT, Msg, Tool\n",
    "\n",
    "GPT_API_KEY_PATH = r\"C:\\Users\\nagen\\Desktop\\gpt\\project_apollo\\Apollo\\openai_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt api key\n",
    "with open(GPT_API_KEY_PATH, 'r') as f:\n",
    "    gpt = GPT(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Assistant is to respond in yes and no only\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Is apple red?\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "msg = GPTMsges(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gptmsg = Msg(gpt, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, response_entry, result = gptmsg.call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response: ChatCompletion(id='chatcmpl-9inhINDXgBKjsppAL695q2HIrVD72', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Yes', role='assistant', function_call=None, tool_calls=None))], created=1720464496, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=24, total_tokens=25))\n",
      "response_entry: {'content': 'Yes', 'role': 'assistant'}\n",
      "result: Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "response: {response}\n",
    "response_entry: {response_entry}\n",
    "result: {result}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_callable(question):\n",
    "    return question\n",
    "\n",
    "tool_definition = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"question_difficulty\",\n",
    "        \"description\": \"\"\"\n",
    "            gets the question asked by the user\n",
    "        \"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"question\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"question asked by the user\",\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "tool = GPTToolPrompt(tool_definition)\n",
    "\n",
    "prompts = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Assistant is to respond in yes and no only\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Have you commited a crime?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "msg = GPTMsges(prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpttool = Tool(gpt, msg, tool, tool_callable, \"required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, response_entry, result = gpttool.call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response: ChatCompletion(id='chatcmpl-9hE9sCWrxvTXW8TFYBQwKsmjMWBDV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_N5nJblIpRQAIxO2s6zIRdcrT', function=Function(arguments='{\"question\":\"Have you commited a crime?\"}', name='question_difficulty'), type='function')]))], created=1720089556, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=74, total_tokens=93))\n",
      "response_entry: {'content': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_N5nJblIpRQAIxO2s6zIRdcrT', 'function': {'arguments': '{\"question\":\"Have you commited a crime?\"}', 'name': 'question_difficulty'}, 'type': 'function'}]}\n",
      "result: (True, {'question_difficulty': ['Have you commited a crime?']})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "response: {response}\n",
    "response_entry: {response_entry}\n",
    "result: {result}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
